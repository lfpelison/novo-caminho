{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read file into pandas using a relative path\n",
    "path = 'data/noticias.csv'\n",
    "news = pd.read_csv(path, delimiter=' ', quotechar='|', names=['index', 'message', 'risk', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>message</th>\n",
       "      <th>risk</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mas quem dirá se será pacto democrático ou lut...</td>\n",
       "      <td>Medio</td>\n",
       "      <td>Manifestacao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Assinado pela presidente nacional do partido, ...</td>\n",
       "      <td>Medio</td>\n",
       "      <td>Politica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PolíticaO deputado federal Vicente Cândido (PT...</td>\n",
       "      <td>Alto</td>\n",
       "      <td>Corrupcao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Trata-se do célebre caso do apartamento tríple...</td>\n",
       "      <td>Medio</td>\n",
       "      <td>Processo-Juridico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Pesquisa divulgada na semana passada pelo site...</td>\n",
       "      <td>Baixo</td>\n",
       "      <td>Eleicoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Uma hipotética condenação de Lula teria como ú...</td>\n",
       "      <td>Medio</td>\n",
       "      <td>Politica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>O que nós queremos é que não inviabilizem o no...</td>\n",
       "      <td>Medio</td>\n",
       "      <td>Manifestacao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Eu estou quase falando: 'Moro, meu amigo Moro...</td>\n",
       "      <td>Alto</td>\n",
       "      <td>Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Repetiu que, \"se for necessário, será candidat...</td>\n",
       "      <td>Alto</td>\n",
       "      <td>Processo-Juridico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>O MPF pedirá o aumento da pena de Palocci e do...</td>\n",
       "      <td>Alto</td>\n",
       "      <td>Corrupcao</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            message   risk  \\\n",
       "0      0  Mas quem dirá se será pacto democrático ou lut...  Medio   \n",
       "1      1  Assinado pela presidente nacional do partido, ...  Medio   \n",
       "2      2  PolíticaO deputado federal Vicente Cândido (PT...   Alto   \n",
       "3      3  Trata-se do célebre caso do apartamento tríple...  Medio   \n",
       "4      4  Pesquisa divulgada na semana passada pelo site...  Baixo   \n",
       "5      5  Uma hipotética condenação de Lula teria como ú...  Medio   \n",
       "6      6  O que nós queremos é que não inviabilizem o no...  Medio   \n",
       "7      7  \"Eu estou quase falando: 'Moro, meu amigo Moro...   Alto   \n",
       "8      8  Repetiu que, \"se for necessário, será candidat...   Alto   \n",
       "9      9  O MPF pedirá o aumento da pena de Palocci e do...   Alto   \n",
       "\n",
       "            category  \n",
       "0       Manifestacao  \n",
       "1           Politica  \n",
       "2          Corrupcao  \n",
       "3  Processo-Juridico  \n",
       "4           Eleicoes  \n",
       "5           Politica  \n",
       "6       Manifestacao  \n",
       "7              Crime  \n",
       "8  Processo-Juridico  \n",
       "9          Corrupcao  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the first 10 rows\n",
    "news.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = news.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Mas quem dirá se será pacto democrático ou lut...\n",
       "1    Assinado pela presidente nacional do partido, ...\n",
       "2    PolíticaO deputado federal Vicente Cândido (PT...\n",
       "3    Trata-se do célebre caso do apartamento tríple...\n",
       "4    Pesquisa divulgada na semana passada pelo site...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Option at 0x7f3e10cda8c0: --verbose>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from optparse import OptionParser\n",
    "# parse commandline arguments\n",
    "op = OptionParser()\n",
    "op.add_option(\"--lsa\",\n",
    "              dest=\"n_components\", type=\"int\",\n",
    "              help=\"Preprocess documents with latent semantic analysis.\")\n",
    "op.add_option(\"--no-minibatch\",\n",
    "              action=\"store_false\", dest=\"minibatch\", default=True,\n",
    "              help=\"Use ordinary k-means algorithm (in batch mode).\")\n",
    "op.add_option(\"--no-idf\",\n",
    "              action=\"store_false\", dest=\"use_idf\", default=True,\n",
    "              help=\"Disable Inverse Document Frequency feature weighting.\")\n",
    "op.add_option(\"--use-hashing\",\n",
    "              action=\"store_true\", default=False,\n",
    "              help=\"Use a hashing feature vectorizer\")\n",
    "op.add_option(\"--n-features\", type=int, default=10000,\n",
    "              help=\"Maximum number of features (dimensions)\"\n",
    "                   \" to extract from text.\")\n",
    "op.add_option(\"--verbose\",\n",
    "              action=\"store_true\", dest=\"verbose\", default=False,\n",
    "              help=\"Print progress reports inside k-means algorithm.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashing Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<434x10 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 4331 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "TfidfVectorizer(max_df=0.5, max_features=10,\n",
    "                                 min_df=2, use_idf=opts.use_idf)\n",
    "\n",
    "hash_vec = hasher.fit_transform(dataset)\n",
    "hash_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  LSA Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.029\n",
      "Completeness: 0.033\n",
      "V-measure: 0.031\n",
      "Adjusted Rand-Index: 0.003\n",
      "Silhouette Coefficient: 0.085\n",
      "Cluster 0:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'order_centroids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-54fdf1bdb0ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cluster %d:\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morder_centroids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'order_centroids' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn import metrics\n",
    "labels = news.category\n",
    "true_k = np.unique(labels).shape[0]\n",
    "\n",
    "km = MiniBatchKMeans(n_clusters=6, init='k-means++', n_init=1,\n",
    "                     init_size=100000, batch_size=1000)\n",
    "km.fit(hash_vec)\n",
    "\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(labels, km.labels_))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, km.labels_, sample_size=1000))\n",
    "\n",
    "\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i)\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % km[ind])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# equivalently: combine fit and transform into a single step\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "# prepare test data\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 ms, sys: 8 ms, total: 20 ms\n",
      "Wall time: 19.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.65137614678899081"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss = GaussianNB()\n",
    "%time gauss.fit(X_train_dtm.toarray(), y_train)\n",
    "y_pred_gauss = gauss.predict(X_test_dtm.toarray())\n",
    "metrics.accuracy_score(y_test, y_pred_gauss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeghborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 ms, sys: 0 ns, total: 16 ms\n",
      "Wall time: 15.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.55045871559633031"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNC = KNeighborsClassifier(n_neighbors=100)\n",
    "%time KNC.fit(X_train_dtm.toarray(), y_train)\n",
    "y_pred_KNC = KNC.predict(X_test_dtm.toarray())\n",
    "metrics.accuracy_score(y_test, y_pred_KNC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 504 ms, sys: 32 ms, total: 536 ms\n",
      "Wall time: 471 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.66972477064220182"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randForest = RandomForestClassifier(n_estimators=87, n_jobs=300)\n",
    "%time randForest.fit(X_train_dtm, y_train)\n",
    "y_pred_randForest = randForest.predict(X_test_dtm)\n",
    "metrics.accuracy_score(y_test, y_pred_randForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 100 ms, sys: 8 ms, total: 108 ms\n",
      "Wall time: 104 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.56880733944954132"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "%time dt.fit(X_train_dtm.toarray(), y_train)\n",
    "y_pred_dt = dt.predict(X_test_dtm.toarray())\n",
    "metrics.accuracy_score(y_test, y_pred_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.98 s, sys: 0 ns, total: 5.98 s\n",
      "Wall time: 6.01 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.66055045871559637"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBC = GradientBoostingClassifier()\n",
    "%time GBC.fit(X_train_dtm.toarray(), y_train)\n",
    "y_pred_GBC = GBC.predict(X_test_dtm.toarray())\n",
    "metrics.accuracy_score(y_test, y_pred_GBC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 136 ms, sys: 0 ns, total: 136 ms\n",
      "Wall time: 135 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.74311926605504586"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC(C=5e-1)\n",
    "%time svc.fit(X_train_dtm.toarray(), y_train)\n",
    "y_pred_svc = svc.predict(X_test_dtm.toarray())\n",
    "metrics.accuracy_score(y_test, y_pred_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64220183486238536"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_dtm, y_train)\n",
    "y_pred_clf = clf.predict(X_test_dtm)\n",
    "metrics.accuracy_score(y_test, y_pred_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthogonal Matching Pursuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 412 ms, sys: 0 ns, total: 412 ms\n",
      "Wall time: 405 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.55045871559633031"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort = OrthogonalMatchingPursuit()\n",
    "%time ort.fit(X_train_dtm.toarray(), y_train)\n",
    "y_pred_ort = ort.predict(X_test_dtm.toarray())\n",
    "metrics.accuracy_score(y_test, y_pred_ort.round().clip(1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56 ms, sys: 0 ns, total: 56 ms\n",
      "Wall time: 27.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76146788990825687"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=20)\n",
    "lrCV = LogisticRegressionCV()\n",
    "%time lr.fit(X_train_dtm.toarray(), y_train)\n",
    "y_pred_lr = lr.predict(X_test_dtm.toarray())\n",
    "metrics.accuracy_score(y_test, y_pred_lr)\n",
    "#%time lrCV.fit(X_train_dtm.toarray(), y_train)\n",
    "#y_pred_lrCV = lrCV.predict(X_test_dtm.toarray())\n",
    "#metrics.accuracy_score(y_test, y_pred_lrCV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
